@inproceedings{10.1145/3769394.3769410, title = {Sustainable Machine Learning: Course 1}, booktitle = {Proceedings of the Conference on 6th ACM Europe Summer School on Data Science}, pages = {16}, year = {2025}, doi = {10.1145/3769394.3769410}, url = {https://doi.org/10.1145/3769394.3769410}, author = {Kemme, Bettina}, abstract = {Machine learning has become increasingly data and processing hungry. A recent report from the International Energy Agency projects that the electricity demand for data centers specialized in AI will more than quadruple by 2030. As such, it has become a pressing need to include energy awareness and environmental sustainability into the Machine Learning life cycle. In fact, a considerable amount of research efforts have been conducted in the last years in this direction.The first part of this tutorial will discuss various mechanisms to assess the environmental impact of machine learning, from power and energy consumption to carbon footprint. This will be put in relation to more traditional performance metrics used in the research literature, from the "goodness" of a ML solution, measured by metrics such as accuracy, to systems performance metrics such as runtime, throughput and scalability. From there, the tutorial will present several concrete research efforts for a quantitative analysis of the environmental footprint of various ML tasks.The second part of the tutorial will outline recent solutions to tackle the huge energy consumption of modern ML. For instance, there have been an increasing number of research efforts to make both the learning and the inference tasks more efficient while providing similar performance in terms of traditional ML performance metrics such as accuracy. A further line of research focuses on adjusting the infrastructure or the execution of ML tasks to be more energy aware, e.g., through scheduling approaches.} }
@article{10.1145/3664595, title = {Creativity and Machine Learning: A Survey}, journal = {ACM Comput. Surv.}, volume = {56}, year = {2024}, issn = {0360-0300}, doi = {10.1145/3664595}, url = {https://doi.org/10.1145/3664595}, author = {Franceschelli, Giorgio and Musolesi, Mirco}, keywords = {Computational creativity, machine learning, generative deep learning, creativity evaluation methods}, abstract = {There is a growing interest in the area of machine learning and creativity. This survey presents an overview of the history and the state of the art of computational creativity theories, key machine learning techniques (including generative deep learning), and corresponding automatic evaluation methods. After presenting a critical discussion of the key contributions in this area, we outline the current research challenges and emerging opportunities in this field.} }
@inproceedings{10.1145/3680532.3689591, title = {Introduction to Generative Machine Learning}, booktitle = {SIGGRAPH Asia 2024 Courses}, year = {2024}, isbn = {9798400711350}, doi = {10.1145/3680532.3689591}, url = {https://doi.org/10.1145/3680532.3689591}, author = {Sharma, Rajesh and Tang, Mia} }
@inproceedings{10.1145/3610538.3614646, title = {Machine Learning \&amp; Neural Networks}, booktitle = {SIGGRAPH Asia 2023 Courses}, year = {2023}, isbn = {9798400703096}, doi = {10.1145/3610538.3614646}, url = {https://doi.org/10.1145/3610538.3614646}, author = {Sharma, Rajesh and Tang, Mia}, abstract = {Use and development of computer systems that are able to learn and adapt without following explicit instructions by using algorithms and statistical models to analyze and draw inferences from patterns in data.} }
@article{10.1145/3687230.3687232, title = {Planter: Rapid Prototyping of In-Network Machine Learning Inference}, journal = {SIGCOMM Comput. Commun. Rev.}, volume = {54}, pages = {2--21}, year = {2024}, issn = {0146-4833}, doi = {10.1145/3687230.3687232}, url = {https://doi.org/10.1145/3687230.3687232}, author = {Zheng, Changgang and Zang, Mingyuan and Hong, Xinpeng and Perreault, Liam and Bensoussane, Riyad and Vargaftik, Shay and Ben-Itzhak, Yaniv and Zilberman, Noa}, keywords = {P4, dimension reduction, in-network computing, machine learning, machine learning compilers, modular framework, programmable switches}, abstract = {In-network machine learning inference provides high throughput and low latency. It is ideally located within the network, power efficient, and improves applications' performance. Despite its advantages, the bar to in-network machine learning research is high, requiring significant expertise in programmable data planes, in addition to knowledge of machine learning and the application area. Existing solutions are mostly one-time efforts, hard to reproduce, change, or port across platforms. In this paper, we present Planter: a modular and efficient open-source framework for rapid prototyping of in-network machine learning models across a range of platforms and pipeline architectures. By identifying general mapping methodologies for machine learning algorithms, Planter introduces new machine learning mappings and improves existing ones. It provides users with several example use cases and supports different datasets, and was already extended by users to new fields and applications. Our evaluation shows that Planter improves machine learning performance compared with previous model-tailored works, while significantly reducing resource consumption and co-existing with network functionality. Planter-supported algorithms run at line rate on unmodified commodity hardware, providing billions of inference decisions per second.} }
@article{10.1145/3639032, title = {Machine Learning Systems are Bloated and Vulnerable}, journal = {Proc. ACM Meas. Anal. Comput. Syst.}, volume = {8}, year = {2024}, doi = {10.1145/3639032}, url = {https://doi.org/10.1145/3639032}, author = {Zhang, Huaifeng and Alhanahnah, Mohannad and Ahmed, Fahmi Abdulqadir and Fatih, Dyako and Leitner, Philipp and Ali-Eldin, Ahmed}, keywords = {machine learning systems, software debloating}, abstract = {Today's software is bloated with both code and features that are not used by most users. This bloat is prevalent across the entire software stack, from operating systems and applications to containers. Containers are lightweight virtualization technologies used to package code and dependencies, providing portable, reproducible and isolated environments. For their ease of use, data scientists often utilize machine learning containers to simplify their workflow. However, this convenience comes at a cost: containers are often bloated with unnecessary code and dependencies, resulting in very large sizes. In this paper, we analyze and quantify bloat in machine learning containers. We develop MMLB, a framework for analyzing bloat in software systems, focusing on machine learning containers. MMLB measures the amount of bloat at both the container and package levels, quantifying the sources of bloat. In addition, MMLB integrates with vulnerability analysis tools and performs package dependency analysis to evaluate the impact of bloat on container vulnerabilities. Through experimentation with 15 machine learning containers from TensorFlow, PyTorch, and Nvidia, we show that bloat accounts for up to 80\% of machine learning container sizes, increasing container provisioning times by up to 370\% and exacerbating vulnerabilities by up to 99\%.} }
@inproceedings{10.1145/3587423.3595530, title = {Machine Learning \&amp; Neural Networks}, booktitle = {ACM SIGGRAPH 2023 Courses}, year = {2023}, isbn = {9798400701450}, doi = {10.1145/3587423.3595530}, url = {https://doi.org/10.1145/3587423.3595530}, author = {Sharma, Rajesh and Tang, Mia} }
@article{10.1145/3711699, title = {Exploring Function Granularity for Serverless Machine Learning Application with GPU Sharing}, journal = {Proc. ACM Meas. Anal. Comput. Syst.}, volume = {9}, year = {2025}, doi = {10.1145/3711699}, url = {https://doi.org/10.1145/3711699}, author = {Hui, Xinning and Xu, Yuanchao and Shen, Xipeng}, keywords = {cloud computing, deep learning, function granularity, function-as-a-service, machine learning for systems, quality of service, serverless computing}, abstract = {Recent years have witnessed increasing interest in machine learning (ML) inferences on serverless computing due to its auto-scaling and cost-effective properties. However, one critical aspect, function granularity, has been largely overlooked, limiting the potential of serverless ML. This paper explores the impact of function granularity on serverless ML, revealing its important effects on the SLO hit rates and resource costs of serverless applications. It further proposes adaptive granularity as an approach to addressing the phenomenon that no single granularity fits all applications and situations. It explores three predictive models and presents programming tools and runtime extensions to facilitate the integration of adaptive granularity into existing serverless platforms. Experiments show adaptive granularity produces up to a 29.2\% improvement in SLO hit rates and up to a 24.6\% reduction in resource costs over the state-of-the-art serverless ML which uses fixed granularity.} }
@inproceedings{10.1145/3638530.3648413, title = {Evolutionary Computation meets Machine Learning for Combinatorial Optimisation}, booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion}, pages = {1328--1351}, year = {2024}, isbn = {9798400704956}, doi = {10.1145/3638530.3648413}, url = {https://doi.org/10.1145/3638530.3648413}, author = {Mei, Yi and Raidl, G\"unther} }
@inproceedings{10.1145/3627673.3679101, title = {Systems for Scalable Graph Analytics and Machine Learning: Trends and Methods}, booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management}, pages = {5547--5550}, year = {2024}, isbn = {9798400704369}, doi = {10.1145/3627673.3679101}, url = {https://doi.org/10.1145/3627673.3679101}, author = {Yan, Da and Yuan, Lyuheng and Ahmad, Akhlaque and Adhikari, Saugat}, keywords = {GNN, graph, graph neural network, structure, subgraph, system, vertex, location = Boise, ID, USA}, abstract = {Graph-theoretic algorithms and graph machine learning models are essential tools for addressing many real-life problems, such as social network analysis and bioinformatics. To support large-scale graph analytics, graph-parallel systems have been actively developed for over one decade, such as Google's Pregel and Spark's GraphX, which (i) promote a think-like-a-vertex computing model and target (ii) iterative algorithms and (iii) those problems that output a value for each vertex. However, this model is too restricted for supporting the rich set of heterogeneous operations for graph analytics and machine learning that many real applications demand.In recent years, two new trends emerge in graph-parallel systems research: (1) a novel think-like-a-task computing model that can efficiently support the various computationally expensive problems of subgraph search; and (2) scalable systems for learning graph neural networks. These systems effectively complement the diversity needs of graph-parallel tools that can flexibly work together in a comprehensive graph processing pipeline for real applications, with the capability of capturing structural features. This tutorial will provide an effective categorization of the recent systems in these two directions based on their computing models and adopted techniques, and will review the key design ideas of these systems.} }
@article{10.1145/3561381, title = {Open-world Machine Learning: Applications, Challenges, and Opportunities}, journal = {ACM Comput. Surv.}, volume = {55}, year = {2023}, issn = {0360-0300}, doi = {10.1145/3561381}, url = {https://doi.org/10.1145/3561381}, author = {Parmar, Jitendra and Chouhan, Satyendra and Raychoudhury, Vaskar and Rathore, Santosh}, keywords = {Open-world Machine Learning, continual machine learning, incremental learning, open-world image and text classification}, abstract = {Traditional machine learning, mainly supervised learning, follows the assumptions of closed-world learning, i.e., for each testing class, a training class is available. However, such machine learning models fail to identify the classes, which were not available during training time. These classes can be referred to as unseen classes. Open-world Machine Learning (OWML) is a novel technique, which deals with unseen classes. Although OWML is around for a few years and many significant research works have been carried out in this domain, there is no comprehensive survey of the characteristics, applications, and impact of OWML on the major research areas. In this article, we aimed to capture the different dimensions of OWML with respect to other traditional machine learning models. We have thoroughly analyzed the existing literature and provided a novel taxonomy of OWML considering its two major application domains: Computer Vision and Natural Language Processing. We listed the available software packages and open datasets in OWML for future researchers. Finally, the article concludes with a set of research gaps, open challenges, and future directions.} }
@inproceedings{10.1145/3638530.3648408, title = {Evolutionary Art and Design in the Machine Learning Era}, booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion}, pages = {1460--1501}, year = {2024}, isbn = {9798400704956}, doi = {10.1145/3638530.3648408}, url = {https://doi.org/10.1145/3638530.3648408}, author = {Machado, Penousal and Correia, Jo\~ao} }
@article{10.1145/3711702, title = {NetJIT: Bridging the Gap from Traffic Prediction to Preknowledge for Distributed Machine Learning}, journal = {Proc. ACM Meas. Anal. Comput. Syst.}, volume = {9}, year = {2025}, doi = {10.1145/3711702}, url = {https://doi.org/10.1145/3711702}, author = {Ai, Xin and Li, Zijian and Zhu, Yuanyi and Chen, Zixuan and Liu, Sen and Xu, Yang}, keywords = {distributed machine learning, jit, just-in-time program analysis, network optimization, traffic prediction}, abstract = {Today's distributed machine learning (DML) introduces heavy traffic load, making the interconnection network one of the primary bottlenecks. To mitigate this bottleneck, existing state-of-the-art network optimization methods, such as traffic or topology engineering, are proposed to adapt to real-time traffic. However, current traffic measurement and prediction methods struggle to collect sufficiently fine-grained and accurate traffic patterns. This limitation impedes the ability of cutting-edge network optimization techniques to react agilely to the ever-changing traffic demands of DML jobs.This paper proposes NetJIT, a novel program-behavior-aware toolkit for accurately foreseeing the traffic pattern of DML. To the best of our knowledge, this is the first work proposing the use of just-in-time (JIT) program analysis for real-time traffic measurement. In DML applications, communication behavior is primarily determined by the previously computed results. NetJIT leverages this characteristic to anticipate communication details by tracing and analyzing the data relations in the computation process. This capability enables the deployment of optimization strategies in advance.We deploy NetJIT in real-world network optimization for traffic preknowledge. Evaluation with the self-built testbed prototype demonstrates that NetJIT can achieve up to about 97\% less error of detecting communication events compared with other methods. Simulations with real-world DML workloads further illustrate that NetJIT enables more precise network optimization, leading to approximately 50\% better network performance w.r.t the metrics including average iteration time, throughput, and average packet delay.} }
